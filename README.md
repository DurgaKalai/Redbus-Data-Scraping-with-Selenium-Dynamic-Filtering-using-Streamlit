# Redbus-Data-Scraping-with-Selenium-Dynamic-Filtering-using-Streamlit
##  Introduction
This project aims to automate the collection of bus travel data from the RedBus website, which provides essential information like bus routes, schedules, pricing, and seat availability. Using Selenium for web scraping, we will gather data across multiple states and store it in an SQL database for efficient management. Additionally, a Streamlit application will be developed to visualize this data, enabling users to explore and analyze trends easily. This initiative seeks to enhance operational efficiency and support informed decision-making in the transportation industry
## Objective
Develop a Web Scraper: Create a tool to automate the extraction of bus route details, schedules, and relevant information from the RedBus website across multiple states.

Data Storage: Store the collected data in an SQL database for efficient management and easy retrieval.

Data Visualization: Build a Streamlit application to visualize the extracted data, allowing users to interact with and explore the information.

Enhance User Experience: Provide an intuitive platform for users to analyze bus travel data and make informed decisions.

Support Transportation Providers: Equip stakeholders with valuable insights to improve operational efficiency and strategic planning.
## Requirements
This project requires Python 3.x as the programming language, Jupyter Notebook for interactive coding, and MySQL Server for data storage. Visual Studio Code will be used as the code editor, while the Chrome browser is needed for web scraping. Selenium WebDriver will automate browser actions, and Streamlit will be utilized for data visualization.

